export const concepts = [
  // ===============================
  // MODULE 1 — Core LLM Building Blocks
  // ===============================
  { topic: "Tokenization in LLMs", module: 1 },
  { topic: "Byte Pair Encoding (BPE)", module: 1 },
  { topic: "WordPiece and SentencePiece", module: 1 },
  { topic: "Embeddings and Vector Spaces", module: 1 },
  { topic: "Cosine Similarity in Embeddings", module: 1 },

  { topic: "Attention Mechanism", module: 1 },
  { topic: "Self-Attention vs Cross-Attention", module: 1 },
  { topic: "Multi-Head Attention", module: 1 },
  { topic: "Transformers Architecture", module: 1 },
  { topic: "Positional Encoding", module: 1 },

  { topic: "Encoder-Only Models (BERT)", module: 1 },
  { topic: "Decoder-Only Models (GPT)", module: 1 },
  { topic: "Encoder–Decoder Models (T5)", module: 1 },
  { topic: "Context Window and Token Limits", module: 1 },
  { topic: "KV Cache and Faster Inference", module: 1 },

  // ===============================
  // MODULE 2 — Text Generation & Decoding Behaviour
  // ===============================
  { topic: "Logits and Token Probabilities", module: 2 },
  { topic: "Temperature in Text Generation", module: 2 },
  { topic: "Top-K and Top-P Sampling", module: 2 },
  { topic: "Greedy vs Beam Search", module: 2 },
  { topic: "Why LLMs Hallucinate", module: 2 },

  // ===============================
  // MODULE 3 — Prompting & Agentic Workflows
  // ===============================
  { topic: "Prompt Engineering Basics", module: 3 },
  { topic: "System vs User Prompts", module: 3 },
  { topic: "Chain-of-Thought Prompting", module: 3 },
  { topic: "Few-Shot and Zero-Shot Learning", module: 3 },
  { topic: "Function Calling / Tool Calling", module: 3 },

  { topic: "AI Agents and Orchestration", module: 3 },
  { topic: "Task Planning for AI Agents", module: 3 },
  { topic: "Memory and Context Management in AI Agents", module: 3 },
  { topic: "Tool Selection and Routing for AI Agents", module: 3 },
  { topic: "Workflow Orchestration for LLM Apps", module: 3 },

  // ===============================
  // MODULE 4 — Retrieval, Embeddings & RAG
  // ===============================
  { topic: "Retrieval-Augmented Generation (RAG)", module: 4 },
  { topic: "Chunking Strategies for RAG", module: 4 },
  { topic: "Vector Databases (Pinecone, Weaviate, FAISS)", module: 4 },
  { topic: "Semantic Search vs Keyword Search", module: 4 },
  { topic: "Re-ranking and Negative Sampling", module: 4 },

  { topic: "Embedding Models for Semantic Tasks", module: 4 },
  { topic: "Evaluating Embeddings Quality", module: 4 },
  { topic: "Caching Strategies for LLM APIs", module: 4 },

  // ===============================
  // MODULE 5 — Training, Adaptation & Evaluation
  // ===============================
  { topic: "Fine-Tuning vs RAG", module: 5 },
  { topic: "Instruction Tuning", module: 5 },
  { topic: "Domain Adaptation with Custom Datasets", module: 5 },
  { topic: "Synthetic Data Generation with LLMs", module: 5 },

  { topic: "Evaluating LLMs (Evals)", module: 5 },
  { topic: "Online Evaluation and A/B Testing for LLM Features", module: 5 },
  { topic: "Human-in-the-Loop Review Workflows", module: 5 },
  { topic: "Versioning Models, Prompts, and Datasets", module: 5 },

  // ===============================
  // MODULE 6 — Safety, Governance & Compliance
  // ===============================
  { topic: "RLHF — Reinforcement Learning from Human Feedback", module: 6 },
  { topic: "Model Alignment and Safety", module: 6 },
  { topic: "Guardrails and Policy Models", module: 6 },
  { topic: "Safety Testing and Red-Teaming for LLMs", module: 6 },
  { topic: "Bias and Fairness Monitoring in LLM Systems", module: 6 },

  { topic: "Data Privacy and Governance for LLMs", module: 6 },
  { topic: "PII Detection and Redaction in LLM Pipelines", module: 6 },
  { topic: "Regulatory and Compliance Considerations (GDPR, HIPAA)", module: 6 },

  // ===============================
  // MODULE 7 — Infra, Deployment & Cost
  // ===============================
  { topic: "Small Language Models (SLMs)", module: 7 },
  { topic: "Quantization and Model Compression", module: 7 },
  { topic: "Latency, Throughput and Cost", module: 7 },
  { topic: "Batching and Parallel Decoding", module: 7 },

  { topic: "Rate Limiting and Quotas in LLM Systems", module: 7 },
  { topic: "Multi-Tenancy and Access Control for AI Products", module: 7 },
  { topic: "On-Device and Edge Deployment of LLMs", module: 7 },
  { topic: "Choosing Between API vs Self-Hosted LLMs", module: 7 },
  { topic: "Cost Optimization for LLM Products", module: 7 },
  { topic: "Observability for LLM Apps", module: 7 },

  // ===============================
  // MODULE 8 — Product & Domain Use Cases
  // ===============================
  { topic: "Multimodal LLMs (Image + Text + Audio)", module: 8 },
  { topic: "LLMs for Text-to-SQL", module: 8 },
  { topic: "LLMs in Healthcare Applications", module: 8 },
  { topic: "LLMs in Financial Services", module: 8 },
  { topic: "Defining North Star Metrics for LLM Products", module: 8 },
  { topic: "Designing LLM-First Product Experiences", module: 8 }
];
